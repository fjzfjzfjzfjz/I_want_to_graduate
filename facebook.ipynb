{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1596\n",
      "data/facebook/1-1596/friends_1-2000\n",
      "data/facebook/1-1596/about1-2000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-06a351862ecd>\u001B[0m in \u001B[0;36mparse_userinfo\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     62\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m             \u001B[0midx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m':'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m             \u001B[0md\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m':'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'Jönköping University'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-24-06a351862ecd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    128\u001B[0m                  \u001B[1;34m'contact information'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'Relationship'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'Family Members'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'About'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m                  'Favorite Quotes','Gender','Interested In','Languages']\n\u001B[1;32m--> 130\u001B[1;33m             \u001B[0mparse_userinfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    131\u001B[0m \u001B[1;31m#save\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/facebook/char_set.txt'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'w'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-06a351862ecd>\u001B[0m in \u001B[0;36mparse_userinfo\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     82\u001B[0m                 \u001B[1;31m#输入数据\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mthis_part\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;32mcontinue\u001B[0m \u001B[1;31m#不读取的数据\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m                 \u001B[0muser_info_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mthis_part\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m                 \u001B[0muser_info_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mthis_part\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[1;34m' '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mcol\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mthis_part\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0muser_info_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#将friends following整理成文件\n",
    "import os\n",
    "import pickle\n",
    "output_path='data/facebook/followings'\n",
    "lines={}\n",
    "user_info_dict={}\n",
    "user_info_list=[]\n",
    "char_set=set()\n",
    "\n",
    "col=['id','URL','昵称','Education','Work','current_city','hometown',\n",
    "        'contact information','Relationship','Family Members','About',\n",
    "        'Favorite Quotes','Gender','Interested In','Languages']\n",
    "dont_need=['#education','#{#','#}#','#living','#relationship',\n",
    "            '#bio','#year-overviews','total']\n",
    "useless=['@Other Places Lived','@Life Events']\n",
    "rt_dict={'@Education':2,'@Work':3,'@Current City and Hometown':4,'current_city':5,\n",
    "            '@Contact Information':6,'@Basic Information':11,'@Relationship':7,\n",
    "             '@Family Members':8,'@About':9,'@Favorite Quotes':10,'Interested In':12,\n",
    "             'Languages':13}\n",
    "\n",
    "def check_has(x:list,y:str):\n",
    "    for i in x:\n",
    "        if i in y:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def parse(text):\n",
    "    # print(text)\n",
    "    #将每个用户的组合起来，解析出id:[url。。。]\n",
    "    for k in text:\n",
    "        try:\n",
    "            idx=int(k[:k.find(':')])\n",
    "            #开始行\n",
    "            # assert idx not in lines,\"重复处理关系 \"+str(idx)\n",
    "            #TODO 使用entity的编号区分吧，entity重复就选一个\n",
    "            #TODO 过滤无效关系\n",
    "            assert k.count(':')>=3\n",
    "            #https://也有冒号，所以不能split\n",
    "            lines[idx]=[]\n",
    "        except ValueError:\n",
    "            #不是开始行,不处理assert\n",
    "            if 'total' in k or '#{#' in k or '#}#' in k:\n",
    "                continue\n",
    "            assert k.count('#')>=2,k\n",
    "            lines[idx].append(k.split('#')[-1].strip())\n",
    "    return lines\n",
    "\n",
    "#把分隔符视为一样，不区分@Work和没有@等。。\n",
    "def update(this_part,k):\n",
    "    if check_has(useless,k):\n",
    "        return -1\n",
    "    for i in rt_dict:\n",
    "        if i in k:\n",
    "            return rt_dict[i]+1 #因为少写了url。。。\n",
    "\n",
    "\n",
    "def parse_userinfo(text):\n",
    "    # print(text)\n",
    "    #解析出userinfo {id:{}} and [xxx]\n",
    "    for k in text:\n",
    "        try:\n",
    "            idx=int(k[:k.find(':')])\n",
    "            d=k.strip().split(':')\n",
    "            username= d[2].strip() if d[2].strip() else d[1].strip()\n",
    "            #开始行\n",
    "            assert k.count(':')>=3\n",
    "            #https://也有冒号，所以需要组合url\n",
    "            url=':'.join(d[3:])\n",
    "            user_info_dict[idx]={'昵称':username,'URL':url}\n",
    "            user_info_list.append([idx,url,username]+['']*(len(col)-3))\n",
    "            this_part=2 #当前处理的子索引，即Education\n",
    "\n",
    "        except ValueError:\n",
    "            #不是开始行,不处理assert\n",
    "            if check_has(dont_need,k):\n",
    "                continue\n",
    "            if check_has(list(rt_dict.keys())+useless,k):\n",
    "                #更新所在子索引\n",
    "                this_part=update(this_part,k)\n",
    "            else:\n",
    "                #输入数据\n",
    "                if this_part==-1:continue #不读取的数据\n",
    "                user_info_list[this_part]+=k.strip()\n",
    "                user_info_list[this_part]+=' '\n",
    "                if col[this_part] not in user_info_dict[idx]:\n",
    "                    user_info_dict[idx][col[this_part]]=''\n",
    "                user_info_dict[idx][col[this_part]]+=k.strip()\n",
    "                user_info_dict[idx][col[this_part]]+=' '\n",
    "\n",
    "for path in os.listdir('data/facebook'):\n",
    "    print(path)\n",
    "    if not os.path.isdir(f'data/facebook/{path}') or 'following' in path:continue\n",
    "    dd=os.listdir(f'data/facebook/{path}')\n",
    "    name=''\n",
    "    # print(path)\n",
    "    for i in dd:\n",
    "        if 'friend' in i:\n",
    "            name=i\n",
    "            break\n",
    "    assert name != ''\n",
    "    # print(name)\n",
    "    print(f'data/facebook/{path}/{name}')\n",
    "    for file_name in os.listdir(f'data/facebook/{path}/{name}'):\n",
    "        # print(f'data/facebook/{path}/{name}/{file_name}')\n",
    "        if 'log' in file_name:\n",
    "            continue\n",
    "        with open(f'data/facebook/{path}/{name}/{file_name}',encoding='utf-8-sig') as f:\n",
    "            parse(f.readlines())\n",
    "    #提取所有的字符，简便处理直接从文件中读取\n",
    "    name=''\n",
    "    for i in dd:\n",
    "        if 'about' in i:\n",
    "            name=i\n",
    "            break\n",
    "    assert name != ''\n",
    "    print(f'data/facebook/{path}/{name}')\n",
    "    for file_name in os.listdir(f'data/facebook/{path}/{name}'):\n",
    "        # print(f'data/facebook/{path}/{name}/{file_name}')\n",
    "        if 'log' in file_name:\n",
    "            continue\n",
    "        with open(f'data/facebook/{path}/{name}/{file_name}',encoding='utf-8-sig') as f:\n",
    "            for s in f:\n",
    "                char_set|=set(s.strip())\n",
    "            #获得userinfo信息，直接读取为dict，不存成txt\n",
    "        with open(f'data/facebook/{path}/{name}/{file_name}',encoding='utf-8-sig') as f:\n",
    "            col=['id','昵称','Education','Worked','Lived','current_city','hometown',\n",
    "                 'contact information','Relationship','Family Members','About',\n",
    "                 'Favorite Quotes','Gender','Interested In','Languages']\n",
    "            parse_userinfo(f.readlines())\n",
    "#save\n",
    "with open('data/facebook/char_set.txt','w',encoding='utf-8') as f:\n",
    "    f.writelines([i+'\\n' for i in char_set])\n",
    "pickle.dump(char_set,open('data/facebook/char_set.pickle','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28291\n"
     ]
    }
   ],
   "source": [
    "print(len(list(filter(lambda x:not x,lines.values()))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}